{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Sources\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
        "# https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html"
      ],
      "metadata": {
        "id": "gGlupcYRO4p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFStLJiUK_Od"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import statistics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj785bjFK8uU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuYdWao-LB_z"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Junior/Dyanne JP/ABCD_Release4.0_Tabular_Dataset.csv')\n",
        "df_baseline = df[df['eventname'] == 'baseline_year_1_arm_1']\n",
        "df_2year = df[df['eventname'] == '2_year_follow_up_y_arm_1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYhErpDsLYxK"
      },
      "outputs": [],
      "source": [
        "# All participants = 11879, baseline = 11876, 2 year = 10414\n",
        "df['subjectkey'].nunique()\n",
        "df_baseline['subjectkey'].nunique()\n",
        "df_2year['subjectkey'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keaTNJSQPxqI"
      },
      "outputs": [],
      "source": [
        "baseline_2year = pd.merge(df_baseline, df_2year, on='subjectkey', how='left', suffixes=('_baseline', '_2year'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzO27YFmQ-wQ"
      },
      "outputs": [],
      "source": [
        "print('Number of participants with baseline and 2-year data:')\n",
        "both = baseline_2year.shape[0] - baseline_2year['eventname_2year'].isna().sum()\n",
        "print(both)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDMssfKoSTTt"
      },
      "outputs": [],
      "source": [
        "baseline_2year.dropna(subset=['eventname_2year'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUwjrp2mUcLi"
      },
      "outputs": [],
      "source": [
        "check = ['nihtbx_picvocab_uncorrected_baseline','nihtbx_picvocab_uncorrected_2year','nihtbx_flanker_uncorrected_baseline',\n",
        "         'nihtbx_flanker_uncorrected_2year','nihtbx_pattern_uncorrected_baseline','nihtbx_pattern_uncorrected_2year',\n",
        "         'nihtbx_picture_uncorrected_baseline','nihtbx_picture_uncorrected_2year','nihtbx_reading_uncorrected_baseline',\n",
        "         'nihtbx_reading_uncorrected_2year','nihtbx_cryst_uncorrected_baseline','nihtbx_cryst_uncorrected_2year']\n",
        "\n",
        "cleaned = baseline_2year.dropna(subset=check)\n",
        "#(7172,1055)\n",
        "\n",
        "# drop columns that only have NaN values\n",
        "cleaned.dropna(axis=1, how='all', inplace=True)\n",
        "#(7172,892)\n",
        "\n",
        "print('Number of participants with all 5 test scores')\n",
        "print(cleaned.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TfQfLc_ccyj"
      },
      "outputs": [],
      "source": [
        "non_numeric_columns = cleaned.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "print(\"Non-numeric columns:\", non_numeric_columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpLAxv9-evBq"
      },
      "outputs": [],
      "source": [
        "(cleaned['sex_baseline']==cleaned['sex_2year']).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0_akrElf9wc"
      },
      "outputs": [],
      "source": [
        "cleaned = cleaned.drop('sex_2year',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GciMfKXWgT0q"
      },
      "outputs": [],
      "source": [
        "cleaned['sex_baseline'] = cleaned['sex_baseline'].replace({'M': 0, 'F': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTGeDpFMBjCN"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def medianimpute(df):\n",
        "    # Create a copy of the DataFrame to avoid changing the original data\n",
        "    df_imputed = df.copy()\n",
        "\n",
        "    # Identify numeric columns by data type\n",
        "    numeric_cols = df_imputed.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "    # Define the imputer with a median strategy\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "    # Apply the imputer only to the numeric columns\n",
        "    df_imputed[numeric_cols] = imputer.fit_transform(df_imputed[numeric_cols])\n",
        "\n",
        "    return df_imputed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLQ1CEgnCQb-"
      },
      "outputs": [],
      "source": [
        "imputed = medianimpute(cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gec-PGjBl2S6"
      },
      "outputs": [],
      "source": [
        "print('Number of families in the sample')\n",
        "imputed['family_id_baseline'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M14PPOTbkzoA"
      },
      "outputs": [],
      "source": [
        "# nest family in ABCD study site for LME random effect\n",
        "imputed['site_family'] = imputed['abcd_site_baseline'].astype(str) + \"_\" + imputed['family_id_baseline'].astype(str)\n",
        "imputed['site_family'] = imputed['abcd_site_2year'].astype(str) + \"_\" + imputed['family_id_baseline'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfD-dKfOnZao"
      },
      "outputs": [],
      "source": [
        "df_low = imputed[(imputed['income_baseline'] >= 1) & (imputed['income_baseline'] < 7)]\n",
        "df_med = imputed[imputed['income_baseline'].isin([7])]\n",
        "df_high = imputed[(imputed['income_baseline'] > 7) & (imputed['income_baseline'] <= 10)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_diff = pd.DataFrame({\n",
        "    'low_diff_picvocab': df_low['nihtbx_picvocab_uncorrected_2year'] - df_low['nihtbx_picvocab_uncorrected_baseline'],\n",
        "    'low_diff_flanker': df_low['nihtbx_flanker_uncorrected_2year'] - df_low['nihtbx_flanker_uncorrected_baseline'],\n",
        "    'low_diff_pattern': df_low['nihtbx_pattern_uncorrected_2year'] - df_low['nihtbx_pattern_uncorrected_baseline'],\n",
        "    'low_diff_picture': df_low['nihtbx_picture_uncorrected_2year'] - df_low['nihtbx_picture_uncorrected_baseline'],\n",
        "    'low_diff_reading': df_low['nihtbx_reading_uncorrected_2year'] - df_low['nihtbx_reading_uncorrected_baseline']\n",
        "})\n",
        "\n",
        "high_diff = pd.DataFrame({\n",
        "    'high_diff_picvocab': df_high['nihtbx_picvocab_uncorrected_2year'] - df_high['nihtbx_picvocab_uncorrected_baseline'],\n",
        "    'high_diff_flanker': df_high['nihtbx_flanker_uncorrected_2year'] - df_high['nihtbx_flanker_uncorrected_baseline'],\n",
        "    'high_diff_pattern': df_high['nihtbx_pattern_uncorrected_2year'] - df_high['nihtbx_pattern_uncorrected_baseline'],\n",
        "    'high_diff_picture': df_high['nihtbx_picture_uncorrected_2year'] - df_high['nihtbx_picture_uncorrected_baseline'],\n",
        "    'high_diff_reading': df_high['nihtbx_reading_uncorrected_2year'] - df_high['nihtbx_reading_uncorrected_baseline']\n",
        "})\n",
        "\n",
        "df_low = pd.concat([df_low, low_diff], axis=1)\n",
        "df_high = pd.concat([df_high, high_diff], axis=1)"
      ],
      "metadata": {
        "id": "BgsuW_q07_hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMnUI2FaZzHR"
      },
      "outputs": [],
      "source": [
        "low_picvocab_neg = df_low[df_low['low_diff_picvocab']<0]\n",
        "high_picvocab_neg = df_high[df_high['high_diff_picvocab']<0]\n",
        "low_picvocab_pos = df_low[df_low['low_diff_picvocab']>0]\n",
        "high_picvocab_pos = df_high[df_high['high_diff_picvocab']>0]\n",
        "\n",
        "low_flanker_neg = df_low[df_low['low_diff_flanker']<0]\n",
        "high_flanker_neg = df_high[df_high['high_diff_flanker']<0]\n",
        "low_flanker_pos = df_low[df_low['low_diff_flanker']>0]\n",
        "high_flanker_pos = df_high[df_high['high_diff_flanker']>0]\n",
        "\n",
        "low_pattern_neg = df_low[df_low['low_diff_pattern']<0]\n",
        "high_pattern_neg = df_high[df_high['high_diff_pattern']<0]\n",
        "low_pattern_pos = df_low[df_low['low_diff_pattern']>0]\n",
        "high_pattern_pos = df_high[df_high['high_diff_pattern']>0]\n",
        "\n",
        "low_picture_neg = df_low[df_low['low_diff_picture']<0]\n",
        "high_picture_neg = df_high[df_high['high_diff_picture']<0]\n",
        "low_picture_pos = df_low[df_low['low_diff_picture']>0]\n",
        "high_picture_pos = df_high[df_high['high_diff_picture']>0]\n",
        "\n",
        "low_reading_neg = df_low[df_low['low_diff_reading']<0]\n",
        "high_reading_neg = df_high[df_high['high_diff_reading']<0]\n",
        "low_reading_pos = df_low[df_low['low_diff_reading']>0]\n",
        "high_reading_pos = df_high[df_high['high_diff_reading']>0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jjRrtqC3z6x"
      },
      "outputs": [],
      "source": [
        "def drop_non_numeric(df):\n",
        "    return df.select_dtypes(include=[np.number])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "include = [\"KSADS_BD_y_baseline\", \"KSADS_Anx_y_baseline\", \"KSADS_Suicide_y_baseline\", \"KSADS_Sleep_y_baseline\", \"KSADS_total_y_baseline\",\n",
        "                \"KSADS_BD_y_2year\", \"KSADS_Anx_y_2year\", \"KSADS_Eat_y_2year\", \"KSADS_Suicide_y_2year\", \"KSADS_Sleep_y_2year\", \"KSADS_total_y_2year\",\n",
        "                \"KSADS_BD_p_baseline\", \"KSADS_Anx_p_baseline\", \"KSADS_Eat_p_baseline\", \"KSADS_Suicide_p_baseline\", \"KSADS_Sleep_p_baseline\", \"KSADS_total_p_baseline\",\n",
        "                \"KSADS_BD_p_2year\", \"KSADS_Anx_p_2year\", \"KSADS_Eat_p_2year\", \"KSADS_Suicide_p_2year\", \"KSADS_Sleep_p_2year\", \"KSADS_total_p_2year\", \"KSADS_Subst_p_baseline\",\n",
        "                \"KSADS_Subst_p_2year\",'cbcl_internal_baseline','cbcl_internal_2year','cbcl_external_baseline','cbcl_external_2year','cbcl_totprob_baseline','cbcl_totprob_2year',\n",
        "                'upps_premeditation_baseline','upps_premeditation_2year','upps_perseverence_baseline','upps_perseverence_2year','upps_sensation_baseline','upps_sensation_2year',\n",
        "                'upps_negative_baseline','upps_negative_2year','upps_positive_baseline','upps_positive_2year','BIS_baseline','BIS_2year','BAS_RR_baseline','BAS_RR_2year',\n",
        "                'BAS_Drive_baseline','BAS_Drive_2year','BAS_Fun_baseline','BAS_Fun_2year','sleep_disturb_total_baseline','sleep_disturb_total_2year','ELS_total_baseline',\n",
        "                'ELS_total_2year','rh_adi_wsum1_baseline','rh_adi_wsum1_2year','rh_adi_wsum2_baseline','rh_adi_wsum2_2year',\n",
        "                \"risk_alcohol_p_baseline\", \"risk_cigarette_p_baseline\", \"risk_electro_nicotine_p_baseline\", \"risk_marijuana_p_baseline\", \"risk_drug_p_baseline\",\n",
        "                \"risk_med_legal_p_baseline\", \"risk_med_marijuana_p_baseline\", \"risk_med_marijuana_pre_p_baseline\", \"risk_family_med_marijuana_p_baseline\",\n",
        "                \"risk_alcohol_p_2year\", \"risk_cigarette_p_2year\", \"risk_electro_nicotine_p_2year\", \"risk_marijuana_p_2year\", \"risk_drug_p_2year\",\n",
        "                \"risk_med_legal_p_2year\", \"risk_med_marijuana_p_2year\", \"risk_med_marijuana_pre_p_2year\", \"risk_family_med_marijuana_p_2year\",\n",
        "                \"risk_alcohol_y_2year\", \"risk_cigarette_y_2year\", \"risk_electro_nicotine_y_2year\", \"risk_marijuana_y_2year\", \"risk_med_legal_y_2year\", \"risk_med_marijuana_y_2year\",\n",
        "                \"risk_med_marijuana_pre_y_2year\", \"risk_family_med_marijuana_y_2year\", \"risk_drug_y_2year\", \"risk_gas_y_2year\", \"risk_pain_y_2year\", \"risk_anix_y_2year\",\n",
        "                \"risk_stimulant_y_2year\",\"good_school_baseline\", \"good_parent1_baseline\", \"good_parent2_baseline\", \"good_parent_baseline\",\n",
        "                \"good_school_2year\", \"prenatal_tobacco_before_baseline\", \"prenatal_alcohol_max_before_baseline\", \"prenatal_alcohol_avg_before_baseline\", \"prenatal_alcohol_eff_before_baseline\",\n",
        "                \"prenatal_marijuana_before_baseline\", \"prenatal_cocaine_before_baseline\", \"prenatal_heroin_before_baseline\", \"prenatal_oxycontin_before_baseline\", \"prenatal_tobacco_after_baseline\",\n",
        "                \"prenatal_alcohol_max_after_baseline\", \"prenatal_alcohol_avg_after_baseline\", \"prenatal_alcohol_eff_after_baseline\", \"prenatal_marijuana_after_baseline\", \"prenatal_cocaine_after_baseline\",\n",
        "                \"prenatal_heroin_after_baseline\", \"prenatal_oxycontin_after_baseline\", \"prenatal_weeks_baseline\",\"screentime_wkday_tv_baseline\", \"screentime_wkday_videos_baseline\", \"screentime_wkday_games_baseline\",\n",
        "                \"screentime_wkday_texting_baseline\", \"screentime_wkday_sns_baseline\", \"screentime_wkday_videochat_baseline\", \"screentime_wkend_tv_baseline\", \"screentime_wkend_videos_baseline\", \"screentime_wkend_games_baseline\",\n",
        "                \"screentime_wkend_texting_baseline\", \"screentime_wkend_sns_baseline\", \"screentime_wkend_videochat_baseline\", \"screentime_wkday_y_baseline\", \"screentime_wkend_y_baseline\", \"screentime_wkday_p_baseline\",\n",
        "                \"screentime_wkend_p_baseline\",\"screentime_maturegames_baseline\", \"screentime_rmovies_baseline\",\"screentime_addict_p_2year\", \"screentime_risk_p_2year\", \"screentime_maturegames_2year\",\n",
        "                \"screentime_rmovies_2year\",'bpm_total_y_2year','bpm_total_t_baseline','bpm_total_t_2year',\"prosocial_y_baseline\", \"prosocial_p_baseline\", \"detention_baseline\", \"detention_rea_baseline\",\n",
        "                \"friends_boys_baseline\", \"friends_girls_baseline\", \"Cfriends_boys_baseline\", \"Cfriends_girls_baseline\", \"friends_same_baseline\", \"friends_diff_baseline\", \"Cfriends_diff_baseline\", \"Cfriends_same_baseline\",\n",
        "                \"prosocial_y_2year\", \"prosocial_p_2year\", \"friends_boys_2year\", \"friends_girls_2year\", \"Cfriends_boys_2year\", \"Cfriends_girls_2year\", \"friends_same_2year\", \"friends_diff_2year\", \"Cfriends_diff_2year\", \"Cfriends_same_2year\",\n",
        "                \"cpeur2_baseline\", \"eaeur1_baseline\", \"depeur4_baseline\", \"mddeur6_baseline\", \"depmulti_baseline\", \"bmieur4_baseline\", \"bmimulti_baseline\", \"insomniaeur6_baseline\", \"snoringeur1_baseline\", \"iqeur2_baseline\", \"happieur4_baseline\",\n",
        "                \"ghappieur2_baseline\", \"ghappimeaneur1_baseline\", \"ghappihealth6_baseline\", \"alcdep_eurauto_baseline\", \"alcdep_afrauto_baseline\", \"alcdep_metaauto_baseline\", \"asdauto_baseline\", \"aspauto_baseline\", \"bipauto_baseline\", \"cannabisauto_baseline\",\n",
        "                \"crossauto_baseline\", \"drinkauto_baseline\", \"edauto_baseline\", \"neuroticismauto_baseline\", \"ocdauto_baseline\", \"risk4pcauto_baseline\", \"risktolauto_baseline\", \"scz_eurauto_baseline\", \"scz_easauto_baseline\", \"scz_metaauto_baseline\", \"smokerauto_baseline\",\n",
        "                \"worryauto_baseline\", \"anxietyauto_baseline\", \"ptsdeur4_baseline\", \"ptsdmeta6_baseline\", \"adhdeur6_baseline\",\"euro_baseline\", \"sex_baseline\", \"race_g_baseline\", \"parent_identity_baseline\", \"demo_brthdat_v2_baseline\", \"demo_sex_v2_baseline\",\n",
        "                \"gender_identity_baseline\", \"parent_age_baseline\", \"foreign_born_family_baseline\", \"married_baseline\", \"high_educ_baseline\", \"high_educ2_baseline\", \"income_baseline\", \"foreign_born_baseline\", \"religion_prefer_baseline\", \"gay_parent_baseline\",\n",
        "                \"gay_youth_baseline\", \"race_ethnicity_baseline\", \"age_baseline\", \"family_adversity_baseline\", \"height_baseline\", \"weight_baseline\",\"vol_baseline\", \"bmi_baseline\", \"total_ratio_baseline\", \"history_ratio_baseline\",\n",
        "                \"euro_2year\", \"race_g_2year\", \"gay_youth_2year\", \"age_2year\",\"height_2year\", \"weight_2year\",\"vol_2year\", \"bmi_2year\"]"
      ],
      "metadata": {
        "id": "x7QlvkuRt74D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWUFDk6faolR"
      },
      "outputs": [],
      "source": [
        "X = low_picvocab_neg[include]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# low SES - picvocab - negative\n",
        "\n",
        "# X = drop_non_numeric(low_picvocab_neg)\n",
        "y = low_picvocab_neg['nihtbx_picvocab_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ],
      "metadata": {
        "id": "aUdXippqWD9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_picvocab_neg[include]"
      ],
      "metadata": {
        "id": "xTu7P2cTpy3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "MSqZFFvZaZ83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# high SES - picvocab - negative\n",
        "\n",
        "y = high_picvocab_neg['nihtbx_picvocab_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ],
      "metadata": {
        "id": "OqYdiZLcYavN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuvbFQeiEqiN"
      },
      "outputs": [],
      "source": [
        "# high SES - picvocab - negative\n",
        "\n",
        "y = high_picvocab_neg['nihtbx_picvocab_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2'],\n",
        "              'bootstrap': [True,False]}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_picvocab_pos[include]"
      ],
      "metadata": {
        "id": "FZzTiC6st_Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "58eeywR4ad0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# low SES - picvocab - positive\n",
        "\n",
        "y = low_picvocab_pos['nihtbx_picvocab_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ],
      "metadata": {
        "id": "AABNnLvTaeVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPOob4lZHUAT"
      },
      "outputs": [],
      "source": [
        "# low SES - picvocab - positive\n",
        "\n",
        "y = low_picvocab_pos['nihtbx_picvocab_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2'],\n",
        "              'bootstrap': [True,False]}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_picvocab_pos[include]"
      ],
      "metadata": {
        "id": "fOLg9uIg1QMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "QO6mzmLjdg6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# high SES - picvocab - positive\n",
        "\n",
        "y = high_picvocab_pos['nihtbx_picvocab_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ],
      "metadata": {
        "id": "c9OQTtJddWen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2-UtDZuHdHb"
      },
      "outputs": [],
      "source": [
        "# high SES - picvocab - positive\n",
        "\n",
        "y = high_picvocab_pos['nihtbx_picvocab_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2'],\n",
        "              'bootstrap': [True,False]}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_flanker_neg[include]"
      ],
      "metadata": {
        "id": "kTFhZcbZ-fGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "SGxqp9Fzn_Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# low SES - flanker - negative\n",
        "\n",
        "y = low_flanker_neg['nihtbx_flanker_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ],
      "metadata": {
        "id": "Vjuh0ShBoAAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yajEzkrjSQNX"
      },
      "outputs": [],
      "source": [
        "# low SES - flanker - negative\n",
        "\n",
        "y = low_flanker_neg['nihtbx_flanker_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2'],\n",
        "              'bootstrap': [True,False]}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_flanker_neg[include]"
      ],
      "metadata": {
        "id": "Seg7VqoZBOjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# high SES - flanker - negative\n",
        "\n",
        "y = high_flanker_neg['nihtbx_flanker_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ],
      "metadata": {
        "id": "har0o1JVpcrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJJMGvyOUbWB"
      },
      "outputs": [],
      "source": [
        "# high SES - flanker - negative\n",
        "\n",
        "y = high_flanker_neg['nihtbx_flanker_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2'],\n",
        "              'bootstrap': [True,False]}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_flanker_pos[include]"
      ],
      "metadata": {
        "id": "_P2fhVZaVsdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# low SES - flanker - positive\n",
        "\n",
        "y = low_flanker_pos['nihtbx_flanker_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ],
      "metadata": {
        "id": "O-hBaSQiraHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz38GrPaZBS-"
      },
      "outputs": [],
      "source": [
        "# low SES - flanker - positive\n",
        "\n",
        "y = low_flanker_pos['nihtbx_flanker_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2'],\n",
        "              'bootstrap': [True,False]}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_flanker_pos[include]"
      ],
      "metadata": {
        "id": "q3sja5pMV01x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIf31zgijWAc"
      },
      "outputs": [],
      "source": [
        "# high SES - flanker - positive\n",
        "\n",
        "y = high_flanker_pos['nihtbx_flanker_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_pattern_neg[include]"
      ],
      "metadata": {
        "id": "3PBzW1J7V4qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAVH_ny1RZRo"
      },
      "outputs": [],
      "source": [
        "# low SES - pattern - negative\n",
        "\n",
        "y = low_pattern_neg['nihtbx_pattern_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_pattern_neg[include]"
      ],
      "metadata": {
        "id": "T8BKwz7XV_JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5Aw2YAkR7n4"
      },
      "outputs": [],
      "source": [
        "# high SES - pattern - negative\n",
        "\n",
        "y = high_pattern_neg['nihtbx_pattern_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_pattern_pos[include]"
      ],
      "metadata": {
        "id": "pX0aWg9aWBbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####"
      ],
      "metadata": {
        "id": "L7kTY_Ge5h3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCvzwBwTSAlf"
      },
      "outputs": [],
      "source": [
        "# low SES - pattern - positive\n",
        "\n",
        "y = low_pattern_pos['nihtbx_pattern_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_pattern_pos[include]"
      ],
      "metadata": {
        "id": "uvqwjR8wWFCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgwrJ1ZNSJRM"
      },
      "outputs": [],
      "source": [
        "# high SES - pattern - positive\n",
        "\n",
        "y = high_pattern_pos['nihtbx_pattern_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_picture_neg[include]"
      ],
      "metadata": {
        "id": "JzGgu1mlWH78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF18451Bz1_L"
      },
      "outputs": [],
      "source": [
        "# low SES - picture - negative\n",
        "\n",
        "y = low_picture_neg['nihtbx_picture_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_picture_neg[include]"
      ],
      "metadata": {
        "id": "g1HZmwO6WQFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TX4LyEI9aG_"
      },
      "outputs": [],
      "source": [
        "# high SES - picture - negative\n",
        "\n",
        "y = high_picture_neg['nihtbx_picture_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_picture_pos[include]"
      ],
      "metadata": {
        "id": "Cjn-teS7WTIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh5P_qwq9jGX"
      },
      "outputs": [],
      "source": [
        "# low SES - picture - positive\n",
        "\n",
        "y = low_picture_pos['nihtbx_picture_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_picture_pos[include]"
      ],
      "metadata": {
        "id": "B3M_tCFKWWRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAhDjbN99mUG"
      },
      "outputs": [],
      "source": [
        "# high SES - picture - positive\n",
        "\n",
        "y = high_picture_pos['nihtbx_picture_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_reading_neg[include]"
      ],
      "metadata": {
        "id": "3YzOixAFWYvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iP4_A1VUtQ5"
      },
      "outputs": [],
      "source": [
        "# low SES - reading - negative\n",
        "\n",
        "y = low_reading_neg['nihtbx_reading_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_reading_neg[include]"
      ],
      "metadata": {
        "id": "SZxwW_CIWbhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "893xu7rQUyrX"
      },
      "outputs": [],
      "source": [
        "# high SES - reading - negative\n",
        "\n",
        "y = high_reading_neg['nihtbx_reading_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = low_reading_pos[include]"
      ],
      "metadata": {
        "id": "FpYEyt2QWeZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv2X3YuNU9kw"
      },
      "outputs": [],
      "source": [
        "# low SES - reading - positive\n",
        "\n",
        "y = low_reading_pos['nihtbx_reading_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = high_reading_pos[include]"
      ],
      "metadata": {
        "id": "3VobmRN8Wg4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxoRsEBKVCRl"
      },
      "outputs": [],
      "source": [
        "# high SES - reading - positive\n",
        "\n",
        "y = high_reading_pos['nihtbx_reading_uncorrected_2year']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Code adapted from Precept 5 Classification Methods and 7 Decision Trees\n",
        "parameters = {'n_estimators': [50,100,200],\n",
        "              'max_depth': [None,10,20,30],\n",
        "              'min_samples_split': [2,5,10],\n",
        "              'min_samples_leaf': [1,2,4],\n",
        "              'max_features':['sqrt','log2']}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=12)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "model_rf = grid_search.best_estimator_\n",
        "\n",
        "# Feature Importance\n",
        "feature_importances = model_rf.feature_importances_\n",
        "features = list(X.columns)\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Review the importance_df DataFrame to see the importance of each feature\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# # Evaluate the model\n",
        "y_pred = model_rf.predict(X_test)\n",
        "\n",
        "# Evaluate with appropriate regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFieibG+gVspYhq/zuBOqw"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
