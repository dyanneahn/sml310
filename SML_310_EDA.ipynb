{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODatkzn1Q/wXlutY+z7Rwp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import zscore\n",
        "import statsmodels.formula.api as smf\n",
        "import statistics\n",
        "from scipy.stats import gaussian_kde\n",
        "from scipy.integrate import quad\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "xFStLJiUK_Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj785bjFK8uU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Junior/Dyanne JP/ABCD_Release4.0_Tabular_Dataset.csv')\n",
        "df_baseline = df[df['eventname'] == 'baseline_year_1_arm_1']\n",
        "df_2year = df[df['eventname'] == '2_year_follow_up_y_arm_1']"
      ],
      "metadata": {
        "id": "tuYdWao-LB_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All participants = 11879, baseline = 11876, 2 year = 10414\n",
        "df['subjectkey'].nunique()\n",
        "df_baseline['subjectkey'].nunique()\n",
        "df_2year['subjectkey'].nunique()"
      ],
      "metadata": {
        "id": "BYhErpDsLYxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_2year = pd.merge(df_baseline, df_2year, on='subjectkey', how='left', suffixes=('_baseline', '_2year'))"
      ],
      "metadata": {
        "id": "keaTNJSQPxqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of participants with baseline and 2-year data:')\n",
        "both = baseline_2year.shape[0] - baseline_2year['eventname_2year'].isna().sum()\n",
        "print(both)"
      ],
      "metadata": {
        "id": "kzO27YFmQ-wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_2year.dropna(subset=['eventname_2year'], inplace=True)"
      ],
      "metadata": {
        "id": "cDMssfKoSTTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Picture Vocabulary Test - Number of NaNs')\n",
        "picvocab_bs_nan = baseline_2year['nihtbx_picvocab_uncorrected_baseline'].isna().sum()\n",
        "picvocab_2_nan = baseline_2year['nihtbx_picvocab_uncorrected_2year'].isna().sum()\n",
        "print(f'Baseline: {picvocab_bs_nan}')\n",
        "print(f'2-year: {picvocab_2_nan}')\n",
        "###\n",
        "print('Flanker Inhibitory Control and Attention Test - Number of NaNs')\n",
        "flanker_bs_nan = baseline_2year['nihtbx_flanker_uncorrected_baseline'].isna().sum()\n",
        "flanker_2_nan = baseline_2year['nihtbx_flanker_uncorrected_2year'].isna().sum()\n",
        "print(f'Baseline: {flanker_bs_nan}')\n",
        "print(f'2-year: {flanker_2_nan}')\n",
        "###\n",
        "print('List Sorting Working Memory Test - Number of NaNs')\n",
        "list_bs_nan = baseline_2year['nihtbx_list_uncorrected_baseline'].isna().sum()\n",
        "list_2_nan = baseline_2year['nihtbx_list_uncorrected_2year'].isna().sum()\n",
        "print(f'Baseline: {list_bs_nan}')\n",
        "print(f'2-year: {list_2_nan}')\n",
        "###\n",
        "print('Dimensional Change Card Sort Test - Number of NaNs')\n",
        "cardsort_bs_nan = baseline_2year['nihtbx_cardsort_uncorrected_baseline'].isna().sum()\n",
        "cardsort_2_nan = baseline_2year['nihtbx_cardsort_uncorrected_2year'].isna().sum()\n",
        "print(f'Baseline: {cardsort_bs_nan}')\n",
        "print(f'2-year: {cardsort_2_nan}')\n",
        "###\n",
        "print('Pattern Comparison Processing Speed Test - Number of NaNs')\n",
        "pattern_bs_nan = baseline_2year['nihtbx_pattern_uncorrected_baseline'].isna().sum()\n",
        "pattern_2_nan = baseline_2year['nihtbx_pattern_uncorrected_2year'].isna().sum()\n",
        "print(f'Baseline: {pattern_bs_nan}')\n",
        "print(f'2-year: {pattern_2_nan}')\n",
        "###\n",
        "print('Picture Sequence Memory Test - Number of NaNs')\n",
        "picture_bs_nan = baseline_2year['nihtbx_picture_uncorrected_baseline'].isna().sum()\n",
        "picture_2_nan = baseline_2year['nihtbx_picture_uncorrected_2year'].isna().sum()\n",
        "print(f'Baseline: {picture_bs_nan}')\n",
        "print(f'2-year: {picture_2_nan}')\n",
        "###\n",
        "print('Oral Reading Recognition Test - Number of NaNs')\n",
        "reading_bs_nan = baseline_2year['nihtbx_reading_uncorrected_baseline'].isna().sum()\n",
        "reading_2_nan = baseline_2year['nihtbx_reading_uncorrected_2year'].isna().sum()\n",
        "print(f'Baseline: {reading_bs_nan}')\n",
        "print(f'2-year: {reading_2_nan}')"
      ],
      "metadata": {
        "id": "Zmu4T8RKSVwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check = ['nihtbx_picvocab_uncorrected_baseline','nihtbx_picvocab_uncorrected_2year','nihtbx_flanker_uncorrected_baseline',\n",
        "         'nihtbx_flanker_uncorrected_2year','nihtbx_pattern_uncorrected_baseline','nihtbx_pattern_uncorrected_2year',\n",
        "         'nihtbx_picture_uncorrected_baseline','nihtbx_picture_uncorrected_2year','nihtbx_reading_uncorrected_baseline',\n",
        "         'nihtbx_reading_uncorrected_2year','nihtbx_cryst_uncorrected_baseline','nihtbx_cryst_uncorrected_2year']\n",
        "\n",
        "cleaned = baseline_2year.dropna(subset=check)\n",
        "#(7172,1055)\n",
        "\n",
        "# drop columns that only have NaN values\n",
        "cleaned.dropna(axis=1, how='all', inplace=True)\n",
        "#(7172,892)\n",
        "\n",
        "print('Number of participants with all 5 test scores')\n",
        "print(cleaned.shape[0])"
      ],
      "metadata": {
        "id": "qUwjrp2mUcLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_numeric_columns = cleaned.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "print(\"Non-numeric columns:\", non_numeric_columns.tolist())"
      ],
      "metadata": {
        "id": "5TfQfLc_ccyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(cleaned['sex_baseline']==cleaned['sex_2year']).sum()"
      ],
      "metadata": {
        "id": "jpLAxv9-evBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = cleaned.drop('sex_2year',axis=1)"
      ],
      "metadata": {
        "id": "w0_akrElf9wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned['sex_baseline'] = cleaned['sex_baseline'].replace({'M': 0, 'F': 1})"
      ],
      "metadata": {
        "id": "GciMfKXWgT0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned['income_baseline'].unique()"
      ],
      "metadata": {
        "id": "MeXIZlZfoNYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def medianimpute(df):\n",
        "    # Create a copy of the DataFrame to avoid changing the original data\n",
        "    df_imputed = df.copy()\n",
        "\n",
        "    # Identify numeric columns by data type\n",
        "    numeric_cols = df_imputed.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "    # Define the imputer with a median strategy\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "    # Apply the imputer only to the numeric columns\n",
        "    df_imputed[numeric_cols] = imputer.fit_transform(df_imputed[numeric_cols])\n",
        "\n",
        "    return df_imputed"
      ],
      "metadata": {
        "id": "cTGeDpFMBjCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputed = medianimpute(cleaned)"
      ],
      "metadata": {
        "id": "PLQ1CEgnCQb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of families in the sample')\n",
        "imputed['family_id_baseline'].nunique()"
      ],
      "metadata": {
        "id": "gec-PGjBl2S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nest family in ABCD study site for LME random effect\n",
        "imputed['site_family'] = imputed['abcd_site_baseline'].astype(str) + \"_\" + imputed['family_id_baseline'].astype(str)\n",
        "imputed['site_family'] = imputed['abcd_site_2year'].astype(str) + \"_\" + imputed['family_id_baseline'].astype(str)"
      ],
      "metadata": {
        "id": "M14PPOTbkzoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputed['income_baseline'].unique()"
      ],
      "metadata": {
        "id": "zzzvXICeoxGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_low = imputed[(imputed['income_baseline'] >= 1) & (imputed['income_baseline'] < 7)]\n",
        "df_med = imputed[imputed['income_baseline'].isin([7])]\n",
        "df_high = imputed[(imputed['income_baseline'] > 7) & (imputed['income_baseline'] <= 10)]"
      ],
      "metadata": {
        "id": "DfD-dKfOnZao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_low.shape[0]) # 1785 in low SES group\n",
        "print(df_med.shape[0]) # 931 in median SES group (7)\n",
        "print(df_high.shape[0]) # 4456 in high SES group"
      ],
      "metadata": {
        "id": "AbkKd7t0n49J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.style.use('default')\n",
        "\n",
        "plt.hist(imputed['income_baseline'],alpha=0.6)\n",
        "plt.xlabel('Income',fontsize=15)\n",
        "plt.ylabel('Frequency',fontsize=15)\n",
        "plt.xlim(1,10)\n",
        "plt.axvline(x=7, color='r', linestyle='--')\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.text(2, 1800, 'Low SES: n=1,785\\nHigh SES: n=4,456', fontsize=15, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-hvcoq4Xs2mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stacked bar chart\n",
        "plt.hist([df_high['race_ethnicity_baseline'], df_low['race_ethnicity_baseline']], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5], rwidth=0.9, alpha=0.6,\n",
        "         stacked=True, label=['High SES', 'Low SES'])\n",
        "# plt.hist([df_high['race_ethnicity_baseline'], df_low['race_ethnicity_baseline']], bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5], rwidth=0.9, alpha=0.6,\n",
        "#          stacked=True, label=['High SES', 'Low SES'],density=True)\n",
        "plt.xlim(0.5, 5.5)\n",
        "labels = ['White', 'Black', 'Hispanic', 'Asian', 'Other']\n",
        "plt.xticks(range(1, 6),labels,fontsize=15)\n",
        "plt.xlabel('Race',fontsize=15)\n",
        "plt.ylabel('Frequency',fontsize=15)\n",
        "# plt.ylabel('Density',fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8QrTJ7F5kANl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_picvocab_uncorrected_baseline'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 38,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Picture Vocabulary Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Baseline', fontsize=13)\n",
        "plt.ylim(35,130)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eRsJ5zOatX2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_picvocab_uncorrected_2year'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 38,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Picture Vocabulary Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('2-year Follow-up', fontsize=13)\n",
        "plt.ylim(35,130)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u78DFKngInxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set y lim\n",
        "# print(imputed['nihtbx_flanker_uncorrected_baseline'].min())\n",
        "# print(imputed['nihtbx_flanker_uncorrected_2year'].min())\n",
        "# print(imputed['nihtbx_flanker_uncorrected_baseline'].max())\n",
        "# print(imputed['nihtbx_flanker_uncorrected_2year'].max())"
      ],
      "metadata": {
        "id": "mKLQPTBoKdI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_flanker_uncorrected_baseline'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 52,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Flanker Inhibitory Control and Attention Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Baseline', fontsize=13)\n",
        "plt.ylim(50,120)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LGbxEE2d-x-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_flanker_uncorrected_2year'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 52,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Flanker Inhibitory Control and Attention Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('2-year Follow-up', fontsize=13)\n",
        "plt.ylim(50,120)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6NaqBv1VKwdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set y lim\n",
        "# print(imputed['nihtbx_pattern_uncorrected_baseline'].min())\n",
        "# print(imputed['nihtbx_pattern_uncorrected_2year'].min())\n",
        "# print(imputed['nihtbx_pattern_uncorrected_baseline'].max())\n",
        "# print(imputed['nihtbx_pattern_uncorrected_2year'].max())"
      ],
      "metadata": {
        "id": "Qcxc-EFWK-jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_pattern_uncorrected_baseline'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 29,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Pattern Comparison Processing Speed Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Baseline', fontsize=13)\n",
        "plt.ylim(25,170)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BUib6Ep5HwRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_pattern_uncorrected_2year'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 29,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Pattern Comparison Processing Speed Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('2-year Follow-up', fontsize=13)\n",
        "plt.ylim(25,170)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RTBY1hI0LO-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set ylim\n",
        "# print(imputed['nihtbx_picture_uncorrected_baseline'].min())\n",
        "# print(imputed['nihtbx_picture_uncorrected_2year'].min())\n",
        "# print(imputed['nihtbx_picture_uncorrected_baseline'].max())\n",
        "# print(imputed['nihtbx_picture_uncorrected_2year'].max())"
      ],
      "metadata": {
        "id": "YWH05STHLaHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_picture_uncorrected_baseline'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 71.5,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Picture Sequence Memory Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Baseline', fontsize=13)\n",
        "plt.ylim(70,140)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j3CudvcWIBmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_picture_uncorrected_2year'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 71.5,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Picture Sequence Memory Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('2-year Follow-up', fontsize=13)\n",
        "plt.ylim(70,140)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kdvU2GzWLv2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set y lim\n",
        "# print(imputed['nihtbx_reading_uncorrected_baseline'].min())\n",
        "# print(imputed['nihtbx_reading_uncorrected_2year'].min())\n",
        "# print(imputed['nihtbx_reading_uncorrected_baseline'].max())\n",
        "# print(imputed['nihtbx_reading_uncorrected_2year'].max())"
      ],
      "metadata": {
        "id": "HMPMNr_VMKRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_reading_uncorrected_baseline'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 60,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Oral Reading Recognition Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Baseline', fontsize=13)\n",
        "plt.ylim(55,125)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ebf3pWenIVsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imputed['income_baseline'].values\n",
        "y = imputed['nihtbx_reading_uncorrected_2year'].values\n",
        "\n",
        "# Add constant to x to represent the intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Fit the model using statsmodels\n",
        "model = sm.OLS(y_train, x_train).fit()\n",
        "\n",
        "# Print the summary to see the p-value, coefficients, R-squared, etc.\n",
        "print(model.summary())\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate R^2 score for the test set\n",
        "r2_test = metrics.r2_score(y_test, y_pred)\n",
        "print(f\"R^2 score for the test set: {r2_test:.4f}\")\n",
        "\n",
        "p_value = model.pvalues[1]  # Assuming index 1 is for 'income_baseline'\n",
        "print(f\"The p-value for the income coefficient is: {p_value}\")\n",
        "\n",
        "b, w = model.params\n",
        "\n",
        "plt.scatter(x_test[:, 1], y_test, color='blue', alpha=0.5)  # x_test[:, 1] because x_test includes the constant\n",
        "plt.plot(x_test[:, 1], y_pred, color='red')\n",
        "plt.text(1, 60,f\"y={w:0.2f}x+{b:0.2f}\", fontsize=13)\n",
        "plt.xticks(ticks=[1,2,3,4,5,6,7,8,9,10], labels=['1','2','3','4','5','6','7','8','9','10'], fontsize=13)\n",
        "plt.xlabel('Income',fontsize=13)\n",
        "plt.ylabel('Oral Reading Recognition Test',fontsize=12)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('2-year Follow-up', fontsize=13)\n",
        "plt.ylim(55,125)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ydRqBTujNEGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_diff_picvocab = df_high['nihtbx_picvocab_uncorrected_2year']-df_high['nihtbx_picvocab_uncorrected_baseline']\n",
        "low_diff_picvocab = df_low['nihtbx_picvocab_uncorrected_2year']-df_low['nihtbx_picvocab_uncorrected_baseline']\n",
        "\n",
        "high_diff_flanker = df_high['nihtbx_flanker_uncorrected_2year']-df_high['nihtbx_flanker_uncorrected_baseline']\n",
        "low_diff_flanker = df_low['nihtbx_flanker_uncorrected_2year']-df_low['nihtbx_flanker_uncorrected_baseline']\n",
        "\n",
        "high_diff_pattern = df_high['nihtbx_pattern_uncorrected_2year']-df_high['nihtbx_pattern_uncorrected_baseline']\n",
        "low_diff_pattern = df_low['nihtbx_pattern_uncorrected_2year']-df_low['nihtbx_pattern_uncorrected_baseline']\n",
        "\n",
        "high_diff_picture = df_high['nihtbx_picture_uncorrected_2year']-df_high['nihtbx_picture_uncorrected_baseline']\n",
        "low_diff_picture = df_low['nihtbx_picture_uncorrected_2year']-df_low['nihtbx_picture_uncorrected_baseline']\n",
        "\n",
        "high_diff_reading = df_high['nihtbx_reading_uncorrected_2year']-df_high['nihtbx_reading_uncorrected_baseline']\n",
        "low_diff_reading = df_low['nihtbx_reading_uncorrected_2year']-df_low['nihtbx_reading_uncorrected_baseline']"
      ],
      "metadata": {
        "id": "myN7kVCoe-V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_prop_picvocab_pos = (high_diff_picvocab > 0).sum() / high_diff_picvocab.size\n",
        "low_prop_picvocab_pos = (low_diff_picvocab > 0).sum() / low_diff_picvocab.size\n",
        "high_prop_picvocab_neg = (high_diff_picvocab < 0).sum() / high_diff_picvocab.size\n",
        "low_prop_picvocab_neg = (low_diff_picvocab < 0).sum() / low_diff_picvocab.size\n",
        "\n",
        "high_prop_flanker_pos = (high_diff_flanker > 0).sum() / high_diff_flanker.size\n",
        "low_prop_flanker_pos = (low_diff_flanker > 0).sum() / low_diff_flanker.size\n",
        "high_prop_flanker_neg = (high_diff_flanker < 0).sum() / high_diff_flanker.size\n",
        "low_prop_flanker_neg = (low_diff_flanker < 0).sum() / low_diff_flanker.size\n",
        "\n",
        "high_prop_pattern_pos = (high_diff_pattern > 0).sum() / high_diff_pattern.size\n",
        "low_prop_pattern_pos = (low_diff_pattern > 0).sum() / low_diff_pattern.size\n",
        "high_prop_pattern_neg = (high_diff_pattern < 0).sum() / high_diff_pattern.size\n",
        "low_prop_pattern_neg = (low_diff_pattern < 0).sum() / low_diff_pattern.size\n",
        "\n",
        "high_prop_picture_pos = (high_diff_picture > 0).sum() / high_diff_picture.size\n",
        "low_prop_picture_pos = (low_diff_picture > 0).sum() / low_diff_picture.size\n",
        "high_prop_picture_neg = (high_diff_picture < 0).sum() / high_diff_picture.size\n",
        "low_prop_picture_neg = (low_diff_picture < 0).sum() / low_diff_picture.size\n",
        "\n",
        "high_prop_reading_pos = (high_diff_reading > 0).sum() / high_diff_reading.size\n",
        "low_prop_reading_pos = (low_diff_reading > 0).sum() / low_diff_reading.size\n",
        "high_prop_reading_neg = (high_diff_reading < 0).sum() / high_diff_reading.size\n",
        "low_prop_reading_neg = (low_diff_reading < 0).sum() / low_diff_reading.size"
      ],
      "metadata": {
        "id": "WeZac37qmdN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_kde_picvocab = gaussian_kde(high_diff_picvocab)\n",
        "low_kde_picvocab = gaussian_kde(low_diff_picvocab)\n",
        "\n",
        "high_area_picvocab_pos, _ = quad(high_kde_picvocab, 0, np.inf)\n",
        "low_area_picvocab_pos, _ = quad(low_kde_picvocab, 0, np.inf)\n",
        "high_area_picvocab_neg, _ = quad(high_kde_picvocab, -np.inf, 0)\n",
        "low_area_picvocab_neg, _ = quad(low_kde_picvocab, -np.inf, 0)\n",
        "##\n",
        "high_kde_flanker = gaussian_kde(high_diff_flanker)\n",
        "low_kde_flanker = gaussian_kde(low_diff_flanker)\n",
        "\n",
        "high_area_flanker_pos, _ = quad(high_kde_flanker, 0, np.inf)\n",
        "low_area_flanker_pos, _ = quad(low_kde_flanker, 0, np.inf)\n",
        "high_area_flanker_neg, _ = quad(high_kde_flanker, -np.inf, 0)\n",
        "low_area_flanker_neg, _ = quad(low_kde_flanker, -np.inf, 0)\n",
        "##\n",
        "high_kde_pattern = gaussian_kde(high_diff_pattern)\n",
        "low_kde_pattern = gaussian_kde(low_diff_pattern)\n",
        "\n",
        "high_area_pattern_pos, _ = quad(high_kde_pattern, 0, np.inf)\n",
        "low_area_pattern_pos, _ = quad(low_kde_pattern, 0, np.inf)\n",
        "high_area_pattern_neg, _ = quad(high_kde_pattern, -np.inf, 0)\n",
        "low_area_pattern_neg, _ = quad(low_kde_pattern, -np.inf, 0)\n",
        "##\n",
        "high_kde_picture = gaussian_kde(high_diff_picture)\n",
        "low_kde_picture = gaussian_kde(low_diff_picture)\n",
        "\n",
        "high_area_picture_pos, _ = quad(high_kde_picture, 0, np.inf)\n",
        "low_area_picture_pos, _ = quad(low_kde_picture, 0, np.inf)\n",
        "high_area_picture_neg, _ = quad(high_kde_picture, -np.inf, 0)\n",
        "low_area_picture_neg, _ = quad(low_kde_picture, -np.inf, 0)\n",
        "##\n",
        "high_kde_reading = gaussian_kde(high_diff_reading)\n",
        "low_kde_reading = gaussian_kde(low_diff_reading)\n",
        "\n",
        "high_area_reading_pos, _ = quad(high_kde_reading, 0, np.inf)\n",
        "low_area_reading_pos, _ = quad(low_kde_reading, 0, np.inf)\n",
        "high_area_reading_neg, _ = quad(high_kde_reading, -np.inf, 0)\n",
        "low_area_reading_neg, _ = quad(low_kde_reading, -np.inf, 0)"
      ],
      "metadata": {
        "id": "GLK7oXzkyQqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the proportions for the High SES group\n",
        "counts_high, _ = np.histogram(high_diff_picvocab, bins=25)\n",
        "weights_high = np.ones_like(high_diff_picvocab) / len(high_diff_picvocab)\n",
        "\n",
        "# Calculate the proportions for the Low SES group\n",
        "counts_low, _ = np.histogram(low_diff_picvocab, bins=25)\n",
        "weights_low = np.ones_like(low_diff_picvocab) / len(low_diff_picvocab)\n",
        "\n",
        "data_combined = np.concatenate((high_diff_picvocab, low_diff_picvocab))\n",
        "bins = np.histogram_bin_edges(data_combined, bins=25)\n",
        "\n",
        "# Plot the histograms with proportions on the y-axis\n",
        "plt.hist(high_diff_picvocab, bins=bins, alpha=0.4, label='High SES', weights=weights_high)\n",
        "plt.hist(low_diff_picvocab, bins=bins, alpha=0.4, label='Low SES', weights=weights_low)\n",
        "\n",
        "# Plot customization\n",
        "plt.xlabel('Picture Vocabulary Test (2-year - baseline)', fontsize=13)\n",
        "plt.ylabel('Proportion', fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(25, 0.1, f'High SES > 0: {high_prop_picvocab_pos:0.2f}\\nLow SES > 0: {low_prop_picvocab_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-39, 0.1, f'High SES < 0: {high_prop_picvocab_neg:0.2f}\\nLow SES < 0: {low_prop_picvocab_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X-tYHs_knzbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel density estimation\n",
        "sns.kdeplot(high_diff_picvocab, color='blue', label='High SES')\n",
        "sns.kdeplot(low_diff_picvocab, color='orange', label='Low SES')\n",
        "plt.xlabel('Picture Vocabulary Test (2-year - baseline)',fontsize=13)\n",
        "plt.ylabel('Density',fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(25, 0.03, f'High SES > 0: {high_area_picvocab_pos:0.2f}\\nLow SES > 0: {low_area_picvocab_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-43, 0.03, f'High SES < 0: {high_area_picvocab_neg:0.2f}\\nLow SES < 0: {low_area_picvocab_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "jDCVuICNf5Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the proportions for the High SES group\n",
        "counts_high, _ = np.histogram(high_diff_flanker, bins=25)\n",
        "weights_high = np.ones_like(high_diff_flanker) / len(high_diff_flanker)\n",
        "\n",
        "# Calculate the proportions for the Low SES group\n",
        "counts_low, _ = np.histogram(low_diff_flanker, bins=25)\n",
        "weights_low = np.ones_like(low_diff_flanker) / len(low_diff_flanker)\n",
        "\n",
        "data_combined = np.concatenate((high_diff_flanker, low_diff_flanker))\n",
        "bins = np.histogram_bin_edges(data_combined, bins=25)\n",
        "\n",
        "# Plot the histograms with proportions on the y-axis\n",
        "plt.hist(high_diff_flanker, bins=bins, alpha=0.4, label='High SES', weights=weights_high)\n",
        "plt.hist(low_diff_flanker, bins=bins, alpha=0.4, label='Low SES', weights=weights_low)\n",
        "\n",
        "# Plot customization\n",
        "plt.xlabel('Flanker Inhibitory Control and Attention Test (2-year - baseline)', fontsize=11.5)\n",
        "plt.ylabel('Proportion', fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.ylim(0,0.25)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(23, 0.1, f'High SES > 0: {high_prop_flanker_pos:0.2f}\\nLow SES > 0: {low_prop_flanker_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-35, 0.1, f'High SES < 0: {high_prop_flanker_neg:0.2f}\\nLow SES < 0: {low_prop_flanker_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9LBVHQeMuqL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel density estimation\n",
        "sns.kdeplot(high_diff_flanker, color='blue', label='High SES')\n",
        "sns.kdeplot(low_diff_flanker, color='orange', label='Low SES')\n",
        "plt.xlabel('Flanker Inhibitory Control and Attention Test (2-year - baseline)',fontsize=11.5)\n",
        "plt.ylabel('Density',fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(25, 0.03, f'High SES > 0: {high_area_flanker_pos:0.2f}\\nLow SES > 0: {low_area_flanker_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-42, 0.03, f'High SES < 0: {high_area_flanker_neg:0.2f}\\nLow SES < 0: {low_area_flanker_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "hGBp55s42Bj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the proportions for the High SES group\n",
        "counts_high, _ = np.histogram(high_diff_pattern, bins=25)\n",
        "weights_high = np.ones_like(high_diff_pattern) / len(high_diff_pattern)\n",
        "\n",
        "# Calculate the proportions for the Low SES group\n",
        "counts_low, _ = np.histogram(low_diff_pattern, bins=25)\n",
        "weights_low = np.ones_like(low_diff_pattern) / len(low_diff_pattern)\n",
        "\n",
        "data_combined = np.concatenate((high_diff_pattern, low_diff_pattern))\n",
        "bins = np.histogram_bin_edges(data_combined, bins=25)\n",
        "\n",
        "# Plot the histograms with proportions on the y-axis\n",
        "plt.hist(high_diff_pattern, bins=bins, alpha=0.4, label='High SES', weights=weights_high)\n",
        "plt.hist(low_diff_pattern, bins=bins, alpha=0.4, label='Low SES', weights=weights_low)\n",
        "\n",
        "# Plot customization\n",
        "plt.xlabel('Pattern Comparison Processing Speed Test (2-year - baseline)', fontsize=11.5)\n",
        "plt.ylabel('Proportion', fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.ylim(0,0.25)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(40, 0.1, f'High SES > 0: {high_prop_pattern_pos:0.2f}\\nLow SES > 0: {low_prop_pattern_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-55, 0.1, f'High SES < 0: {high_prop_pattern_neg:0.2f}\\nLow SES < 0: {low_prop_pattern_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RHNER0qE270R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel density estimation\n",
        "sns.kdeplot(high_diff_pattern, color='blue', label='High SES')\n",
        "sns.kdeplot(low_diff_pattern, color='orange', label='Low SES')\n",
        "plt.xlabel('Pattern Comparison Processing Speed Test (2-year - baseline)',fontsize=11.5)\n",
        "plt.ylabel('Density',fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(45, 0.01, f'High SES > 0: {high_area_pattern_pos:0.2f}\\nLow SES > 0: {low_area_pattern_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-65,0.01, f'High SES < 0: {high_area_pattern_neg:0.2f}\\nLow SES < 0: {low_area_pattern_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "9s9JgQxj3Sdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the proportions for the High SES group\n",
        "counts_high, _ = np.histogram(high_diff_picture, bins=25)\n",
        "weights_high = np.ones_like(high_diff_picture) / len(high_diff_picture)\n",
        "\n",
        "# Calculate the proportions for the Low SES group\n",
        "counts_low, _ = np.histogram(low_diff_picture, bins=25)\n",
        "weights_low = np.ones_like(low_diff_picture) / len(low_diff_picture)\n",
        "\n",
        "data_combined = np.concatenate((high_diff_picture, low_diff_picture))\n",
        "bins = np.histogram_bin_edges(data_combined, bins=25)\n",
        "\n",
        "# Plot the histograms with proportions on the y-axis\n",
        "plt.hist(high_diff_picture, bins=bins, alpha=0.4, label='High SES', weights=weights_high)\n",
        "plt.hist(low_diff_picture, bins=bins, alpha=0.4, label='Low SES', weights=weights_low)\n",
        "\n",
        "# Plot customization\n",
        "plt.xlabel('Picture Sequence Memory Test (2-year - baseline)', fontsize=11.5)\n",
        "plt.ylabel('Proportion', fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.ylim(0,0.25)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(23, 0.1, f'High SES > 0: {high_prop_picture_pos:0.2f}\\nLow SES > 0: {low_prop_picture_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-46, 0.1, f'High SES < 0: {high_prop_picture_neg:0.2f}\\nLow SES < 0: {low_prop_picture_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nPjnvA9J54tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel density estimation\n",
        "sns.kdeplot(high_diff_picture, color='blue', label='High SES')\n",
        "sns.kdeplot(low_diff_picture, color='orange', label='Low SES')\n",
        "plt.xlabel('Picture Sequence Memory Test (2-year - baseline)',fontsize=11.5)\n",
        "plt.ylabel('Density',fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(28, 0.01, f'High SES > 0: {high_area_picture_pos:0.2f}\\nLow SES > 0: {low_area_picture_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-55,0.01, f'High SES < 0: {high_area_picture_neg:0.2f}\\nLow SES < 0: {low_area_picture_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "kQZRQHJ163eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the proportions for the High SES group\n",
        "counts_high, _ = np.histogram(high_diff_reading, bins=25)\n",
        "weights_high = np.ones_like(high_diff_reading) / len(high_diff_reading)\n",
        "\n",
        "# Calculate the proportions for the Low SES group\n",
        "counts_low, _ = np.histogram(low_diff_reading, bins=25)\n",
        "weights_low = np.ones_like(low_diff_reading) / len(low_diff_reading)\n",
        "\n",
        "data_combined = np.concatenate((high_diff_reading, low_diff_reading))\n",
        "bins = np.histogram_bin_edges(data_combined, bins=25)\n",
        "\n",
        "# Plot the histograms with proportions on the y-axis\n",
        "plt.hist(high_diff_reading, bins=bins, alpha=0.4, label='High SES', weights=weights_high)\n",
        "plt.hist(low_diff_reading, bins=bins, alpha=0.4, label='Low SES', weights=weights_low)\n",
        "\n",
        "# Plot customization\n",
        "plt.xlabel('Oral Reading Recognition Test (2-year - baseline)', fontsize=11.5)\n",
        "plt.ylabel('Proportion', fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.ylim(0,0.55)\n",
        "plt.xlim(-35,65)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(33, 0.18, f'High SES > 0: {high_prop_reading_pos:0.2f}\\nLow SES > 0: {low_prop_reading_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-32, 0.18, f'High SES < 0: {high_prop_reading_neg:0.2f}\\nLow SES < 0: {low_prop_reading_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "unFGy-F-8xIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel density estimation\n",
        "sns.kdeplot(high_diff_reading, color='blue', label='High SES')\n",
        "sns.kdeplot(low_diff_reading, color='orange', label='Low SES')\n",
        "plt.xlabel('Oral Reading Recognition Test (2-year - baseline)',fontsize=11.5)\n",
        "plt.ylabel('Density',fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.xlim(-35,65)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.legend(fontsize=13)\n",
        "plt.text(33, 0.03, f'High SES > 0: {high_area_reading_pos:0.2f}\\nLow SES > 0: {low_area_reading_pos:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.text(-33,0.03, f'High SES < 0: {high_area_reading_neg:0.2f}\\nLow SES < 0: {low_area_reading_neg:0.2f}', fontsize=11, color='black',\n",
        "         bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "yJ_pUQ2Y99xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_average_with_overlaps(data_x, data_y, window_size, overlap):\n",
        "    range_x = np.max(data_x)-np.min(data_x)\n",
        "    step_size = int(window_size * (1 - overlap))\n",
        "    num_windows = int((range_x - window_size) // step_size + 1)\n",
        "\n",
        "    moving_avg = np.zeros(num_windows)\n",
        "\n",
        "    x0 = np.min(data_x)\n",
        "    for i in range(len(moving_avg)):\n",
        "        x1 = x0 + window_size\n",
        "        filt_0 = data_x > x0\n",
        "        filt_1 = data_x < x1\n",
        "        filt = filt_0*filt_1\n",
        "        moving_avg[i] = np.nanmean(data_y[filt])\n",
        "        x0 += step_size\n",
        "\n",
        "    xaxis = np.arange(np.min(data_x),np.max(data_x),range_x/len(moving_avg))\n",
        "\n",
        "    return xaxis,moving_avg\n",
        "\n",
        "window_size = 9\n",
        "overlap_ratio = 0.75"
      ],
      "metadata": {
        "id": "uRW6p9c_Ex-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "low_baseline_age = np.array(df_low.loc[df_low['eventname_baseline'] == 'baseline_year_1_arm_1', 'age_baseline'])\n",
        "low_2year_age = np.array(df_low.loc[df_low['eventname_2year'] == '2_year_follow_up_y_arm_1', 'age_2year'])\n",
        "\n",
        "high_baseline_age = np.array(df_high.loc[df_high['eventname_baseline'] == 'baseline_year_1_arm_1', 'age_baseline'])\n",
        "high_2year_age = np.array(df_high.loc[df_high['eventname_2year'] == '2_year_follow_up_y_arm_1', 'age_2year'])"
      ],
      "metadata": {
        "id": "hIZPYdYhFCsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "low_baseline_picvocab = np.array(df_low.loc[df_low['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_picvocab_uncorrected_baseline'])\n",
        "low_2year_picvocab = np.array(df_low.loc[df_low['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_picvocab_uncorrected_2year'])\n",
        "high_baseline_picvocab = np.array(df_high.loc[df_high['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_picvocab_uncorrected_baseline'])\n",
        "high_2year_picvocab = np.array(df_high.loc[df_high['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_picvocab_uncorrected_2year'])\n",
        "\n",
        "low_baseline_flanker = np.array(df_low.loc[df_low['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_flanker_uncorrected_baseline'])\n",
        "low_2year_flanker = np.array(df_low.loc[df_low['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_flanker_uncorrected_2year'])\n",
        "high_baseline_flanker = np.array(df_high.loc[df_high['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_flanker_uncorrected_baseline'])\n",
        "high_2year_flanker = np.array(df_high.loc[df_high['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_flanker_uncorrected_2year'])\n",
        "\n",
        "low_baseline_pattern = np.array(df_low.loc[df_low['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_pattern_uncorrected_baseline'])\n",
        "low_2year_pattern = np.array(df_low.loc[df_low['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_pattern_uncorrected_2year'])\n",
        "high_baseline_pattern = np.array(df_high.loc[df_high['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_pattern_uncorrected_baseline'])\n",
        "high_2year_pattern = np.array(df_high.loc[df_high['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_pattern_uncorrected_2year'])\n",
        "\n",
        "low_baseline_picture = np.array(df_low.loc[df_low['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_picture_uncorrected_baseline'])\n",
        "low_2year_picture = np.array(df_low.loc[df_low['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_picture_uncorrected_2year'])\n",
        "high_baseline_picture = np.array(df_high.loc[df_high['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_picture_uncorrected_baseline'])\n",
        "high_2year_picture = np.array(df_high.loc[df_high['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_picture_uncorrected_2year'])\n",
        "\n",
        "low_baseline_reading = np.array(df_low.loc[df_low['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_reading_uncorrected_baseline'])\n",
        "low_2year_reading = np.array(df_low.loc[df_low['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_reading_uncorrected_2year'])\n",
        "high_baseline_reading = np.array(df_high.loc[df_high['eventname_baseline'] == 'baseline_year_1_arm_1', 'nihtbx_reading_uncorrected_baseline'])\n",
        "high_2year_reading = np.array(df_high.loc[df_high['eventname_2year'] == '2_year_follow_up_y_arm_1', 'nihtbx_reading_uncorrected_2year'])"
      ],
      "metadata": {
        "id": "a2V7dja7GRSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(low_baseline_age,low_baseline_picvocab, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(low_2year_age,low_2year_picvocab, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "IeVe_r2VG5QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(low_baseline_age, low_baseline_picvocab,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(low_2year_age, low_2year_picvocab,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.ylim(34,125)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Picture Vocabulary Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lL5J6HvuHJ36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.ylim(78,95)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Picture Vocabulary Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GdfsKNHsJkfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(high_baseline_age,high_baseline_picvocab, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(high_2year_age,high_2year_picvocab, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "cYiy2sgxJuD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(high_baseline_age, high_baseline_picvocab,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(high_2year_age, high_2year_picvocab,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.ylim(34,125)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Picture Vocabulary Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Dy4fDuyJ1Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.ylim(78,95)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Picture Vocabulary Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SYrnoPCEKM02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(low_baseline_age,low_baseline_flanker, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(low_2year_age,low_2year_flanker, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "ftvjAJkNKzk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(low_baseline_age, low_baseline_flanker,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(low_2year_age, low_2year_flanker,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Flanker Inhibitory Control and Attention Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pc8LeyaiK3wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.ylim(90,103)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Flanker Inhibitory Control and Attention Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Q7rJYb8LQ7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(high_baseline_age,high_baseline_flanker, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(high_2year_age,high_2year_flanker, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "Y8B7IWycLhkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(high_baseline_age, high_baseline_flanker,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(high_2year_age, high_2year_flanker,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Flanker Inhibitory Control and Attention Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LUv_oVEJLmgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.ylim(90,103)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Flanker Inhibitory Control and Attention Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K432zNAeLwve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(low_baseline_age,low_baseline_pattern, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(low_2year_age,low_2year_pattern, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "9lFOiExRMCAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(low_baseline_age, low_baseline_pattern,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(low_2year_age, low_2year_pattern,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Pattern Comparison Processing Speed Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bV_xdTbVMHvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.ylim(80,112)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Pattern Comparison Processing Speed Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LYfAACAJMS0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(high_baseline_age,high_baseline_pattern, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(high_2year_age,high_2year_pattern, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "-86o0gWpMZv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(high_baseline_age, high_baseline_pattern,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(high_2year_age, high_2year_pattern,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Pattern Comparison Processing Speed Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N3i0ImvhMdku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.ylim(80,112)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Pattern Comparison Processing Speed Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CL0GxL2KMtE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(low_baseline_age,low_baseline_picture, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(low_2year_age,low_2year_picture, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "PWuv9XDeMyIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(low_baseline_age, low_baseline_picture,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(low_2year_age, low_2year_picture,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Picture Sequence Memory Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AAiIcvgWM0ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.ylim(98,114)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Picture Sequence Memory Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NVKctA-cM90x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(high_baseline_age,high_baseline_picture, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(high_2year_age,high_2year_picture, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "6k-DYfarM_53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(high_baseline_age, high_baseline_picture,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(high_2year_age, high_2year_picture,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Picture Sequence Memory Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3nKwvvHsNEe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.ylim(98,114)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Picture Sequence Memory Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "25rBeNfjNZH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(low_baseline_age,low_baseline_reading, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(low_2year_age,low_2year_reading, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "uovo_zRbNaU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(low_baseline_age, low_baseline_reading,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(low_2year_age, low_2year_reading,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Oral Reading Recognition Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oeg8uTyDNeGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,164)\n",
        "plt.ylim(86,98)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Oral Reading Recognition Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('Low SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s3vX1V1iNl4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(high_baseline_age,high_baseline_reading, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(high_2year_age,high_2year_reading, window_size, overlap_ratio)"
      ],
      "metadata": {
        "id": "zHgDoZlNNokg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(high_baseline_age, high_baseline_reading,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(high_2year_age, high_2year_reading,'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Oral Reading Recognition Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "idogYedhNtfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exclude outlier\n",
        "\n",
        "outlier = high_2year_reading.max()\n",
        "# print(outlier)\n",
        "\n",
        "filtered_high_2year_reading = high_2year_reading < outlier\n",
        "\n",
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(high_baseline_age,high_baseline_reading, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(high_2year_age[filtered_high_2year_reading],high_2year_reading[filtered_high_2year_reading], window_size, overlap_ratio)\n",
        "\n",
        "plt.plot(high_baseline_age, high_baseline_reading,'b.',alpha=0.15)\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(high_2year_age[filtered_high_2year_reading], high_2year_reading[filtered_high_2year_reading],'r.',alpha=0.15)\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Oral Reading Recognition Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQvCCB73Oj_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Oral Reading Recognition Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ge9SFDYsNyKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exclude outlier\n",
        "\n",
        "outlier = high_2year_reading.max()\n",
        "# print(outlier)\n",
        "\n",
        "filtered_high_2year_reading = high_2year_reading < outlier\n",
        "\n",
        "xs_bs, moving_avg_cog_bs = moving_average_with_overlaps(high_baseline_age,high_baseline_reading, window_size, overlap_ratio)\n",
        "xs_fu, moving_avg_cog_fu = moving_average_with_overlaps(high_2year_age[filtered_high_2year_reading],high_2year_reading[filtered_high_2year_reading], window_size, overlap_ratio)\n",
        "\n",
        "plt.plot(xs_bs, moving_avg_cog_bs,'b',linewidth=3,label='Baseline')\n",
        "plt.plot(xs_fu, moving_avg_cog_fu,'r',linewidth=3,label='2 year')\n",
        "plt.xlabel('Age (years)',fontsize=13)\n",
        "plt.xlim(106,167)\n",
        "plt.ylim(86,98)\n",
        "plt.xticks(ticks=[108, 120, 132, 144, 156], labels=['9', '10', '11', '12', '13'], fontsize=13)\n",
        "plt.ylabel('Oral Reading Recognition Test',fontsize=13)\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.title('High SES',fontsize=15)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vfE52wDPQCZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}